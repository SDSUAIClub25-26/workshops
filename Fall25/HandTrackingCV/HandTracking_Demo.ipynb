{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8023b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pyautogui\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "print(\"Libraries imported successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa07a56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpHands = mp.solutions.hands\n",
    "hands = mpHands.Hands(max_num_hands=1, min_detection_confidence=0.7)\n",
    "mpDraw = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bda6cdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pyautogui.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88de4428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    cv2.imshow('Output', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afc5555d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    x,y,c = frame.shape\n",
    "    result = hands.process(frame)\n",
    "\n",
    "    if result.multi_hand_landmarks:\n",
    "        handLandmarks = result.multi_hand_landmarks[0]\n",
    "\n",
    "        mpDraw.draw_landmarks(frame, handLandmarks, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "\n",
    "    cv2.imshow('Output', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c648de34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap  = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    x,y,c = frame.shape\n",
    "    result = hands.process(frame)\n",
    "\n",
    "    if result.multi_hand_landmarks:\n",
    "        handLandmarks = result.multi_hand_landmarks[0]\n",
    "\n",
    "        index_x = int(handLandmarks.landmark[8].x * s[0])\n",
    "        index_y = int(handLandmarks.landmark[8].y * s[1])\n",
    "\n",
    "        pyautogui.moveTo(index_x, index_y, _pause=False)\n",
    "\n",
    "        mpDraw.draw_landmarks(frame, handLandmarks, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "\n",
    "    cv2.imshow('Output', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77836759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_distance(handslms, landmark1, landmark2):\n",
    "    x1, y1 = handslms.landmark[landmark1].x, handslms.landmark[landmark2].y\n",
    "    x2, y2 = handslms.landmark[landmark2].x, handslms.landmark[landmark2].y\n",
    "\n",
    "    return ((x1-x2)**2 + (y1-y2)**2)**0.5\n",
    "\n",
    "def is_pinching(handslms, threshold=0.05):\n",
    "    distance = normalized_distance(handslms, 4, 8)\n",
    "    return distance < threshold\n",
    "\n",
    "def advanced_pinch_detection(handslms, threshold=0.04):\n",
    "    \"\"\"\n",
    "    More sophisticated pinch detection considering finger angles\n",
    "    \"\"\"\n",
    "    # Check if thumb and index are extended\n",
    "    thumb_tip = handslms.landmark[4]\n",
    "    thumb_mcp = handslms.landmark[2]  # Thumb MCP joint\n",
    "    index_tip = handslms.landmark[8]\n",
    "    index_pip = handslms.landmark[6]  # Index PIP joint\n",
    "    \n",
    "    # Check if fingers are extended (simple check)\n",
    "    thumb_extended = thumb_tip.y < thumb_mcp.y\n",
    "    index_extended = index_tip.y < index_pip.y\n",
    "    \n",
    "    # Only consider pinch if both fingers are somewhat extended\n",
    "    if thumb_extended and index_extended:\n",
    "        distance = normalized_distance(handslms, 4, 8)\n",
    "        return distance < threshold\n",
    "    \n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f1f43ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap  = cv2.VideoCapture(0)\n",
    "last_click = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    x,y,c = frame.shape\n",
    "    result = hands.process(frame)\n",
    "\n",
    "    if result.multi_hand_landmarks:\n",
    "        handLandmarks = result.multi_hand_landmarks[0]\n",
    "\n",
    "        index_x = int(handLandmarks.landmark[8].x * s[0])\n",
    "        index_y = int(handLandmarks.landmark[8].y * s[1])\n",
    "        thumb_x = int(handLandmarks.landmark[4].x * s[0])\n",
    "        thumb_y = int(handLandmarks.landmark[4].y * s[1])\n",
    "\n",
    "        pyautogui.moveTo(index_x, index_y, _pause=False)\n",
    "\n",
    "        cv2.line(frame, (thumb_x, thumb_y), (index_x, index_y), (0, 255, 0), 3)\n",
    "\n",
    "        if is_pinching(handLandmarks) and time.time() - last_click > 0.5:\n",
    "            pyautogui.click()\n",
    "            last_click = time.time()\n",
    "\n",
    "        \n",
    "        mpDraw.draw_landmarks(frame, handLandmarks, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "\n",
    "    cv2.imshow('Output', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b21f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_dict(dict):\n",
    "    result = 0\n",
    "    for key in dict:\n",
    "        result+= dict[key]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3c41f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap  = cv2.VideoCapture(0)\n",
    "last_click = 0\n",
    "while True:\n",
    "\n",
    "    # capture webcame frame and shape (width and height)\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # flip frame for mirror effect\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    h, w, c = frame.shape\n",
    "\n",
    "    # convert from bgr to rgb for mediapipe, this is optional\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # have mediapipe hands predict hand landmarks\n",
    "    result = hands.process(rgb_frame)\n",
    "\n",
    "    # dict of fingers where key is landmark and value is 1 or 0 (detected or not)\n",
    "    fingers = {\"4\": 0, \"8\": 0, \"12\": 0, \"16\": 0, \"20\": 0}\n",
    "\n",
    "\n",
    "    # check if predicted landmarks were detected\n",
    "    # if so draw & output them to the opencv window\n",
    "    if result.multi_hand_landmarks:\n",
    "        \n",
    "        handLandmarks = result.multi_hand_landmarks[0]\n",
    "        # thumb coordinates\n",
    "\n",
    "        # a note here is we have to scale coordinates relative to the frame (height, width)\n",
    "        x4, y4 = int(handLandmarks.landmark[4].x * w), int(handLandmarks.landmark[4].y * h)\n",
    "        x2, y2 = int(handLandmarks.landmark[2].x * w), int(handLandmarks.landmark[2].y * h)\n",
    "\n",
    "        # check if thumb is up\n",
    "        if x4 > x2:\n",
    "            fingers['4'] = 1\n",
    "        \n",
    "        # index finger coordinates\n",
    "        x8, y8 = int(handLandmarks.landmark[8].x * w), int(handLandmarks.landmark[8].y * h)\n",
    "        x6, y6 = int(handLandmarks.landmark[6].x * w), int(handLandmarks.landmark[6].y * h)\n",
    "\n",
    "        if y8 < y6:\n",
    "            fingers['8'] = 1\n",
    "        \n",
    "        # middle finger\n",
    "        x12, y12 = int(handLandmarks.landmark[12].x * w), int(handLandmarks.landmark[12].y * h)\n",
    "        x10, y10 = int(handLandmarks.landmark[10].x * w), int(handLandmarks.landmark[10].y * h)\n",
    "\n",
    "        if y12 < y10:\n",
    "            fingers['12'] = 1\n",
    "        \n",
    "        # ring finger\n",
    "        x16, y16 = int(handLandmarks.landmark[16].x * w), int(handLandmarks.landmark[16].y * h)\n",
    "        x14, y14 = int(handLandmarks.landmark[14].x * w), int(handLandmarks.landmark[14].y * h)\n",
    "\n",
    "        if y16 < y14:\n",
    "            fingers['16'] = 1\n",
    "        \n",
    "        # pinky finger\n",
    "        x20, y20 = int(handLandmarks.landmark[20].x * w), int(handLandmarks.landmark[20].y * h)\n",
    "        x18, y18 = int(handLandmarks.landmark[18].x * w), int(handLandmarks.landmark[18].y * h)\n",
    "    \n",
    "        if y20 < y18:\n",
    "            fingers['20'] = 1\n",
    "\n",
    "        mpDraw.draw_landmarks(frame, handLandmarks, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "    # count raised fingers\n",
    "    number_fingers = sum_dict(fingers)\n",
    "\n",
    "    # draw finger counter visual\n",
    "    cv2.rectangle(frame, (25, 150), (100, 400), (0, 128, 0), cv2.FILLED)\n",
    "    cv2.putText(frame, str(number_fingers), (35, 300), cv2.FONT_HERSHEY_PLAIN,\n",
    "                3, (0, 71, 71), 2)\n",
    "    \n",
    "    cv2.imshow('Output', frame)\n",
    "    # if q is pressed, program exits\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
